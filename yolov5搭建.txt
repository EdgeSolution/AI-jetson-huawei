# æœ¬æ–‡ä»‹ç»å¦‚ä½•å°†ç»è¿‡è®­ç»ƒçš„æ¨¡å‹éƒ¨ç½²åˆ° NVIDIA Jetson Orin NXå¹³å°ä¸­å¹¶ä½¿ç”¨ TensorRT å’Œ DeepStream SDK æ‰§è¡Œæ¨ç† ###

ã€ é‡è¦æç¤ºï¼šç”±äºå®˜æ–¹ç½‘ç«™åªæä¾› SBSA ARM CPUçš„TensorRTçš„DEBåŒ…ï¼Œæ­¤åŒ…ä¸é€‚ç”¨Jetsonå¹³å°ã€‘
ã€æ‰€ä»¥åªèƒ½é€šè¿‡å®˜æ–¹æºä¸‹è½½cudaï¼ŒtensorRTï¼Œcudnnã€‘
/etc/apt/sources.list.d/nvidia-l4t-apt-source.list
deb https://repo.download.nvidia.com/jetson/common r35.3 main
deb https://repo.download.nvidia.com/jetson/t234 r35.3 main

1. # å®‰è£…ç¯å¢ƒ CUAD-11.4, cuDNN-8.6, torch-2.1.0, torchvision-0.16.0 #
apt install cuda-11-4 
apt install libfreeimage-dev libcudnn8 libcudnn8-dev libcudnn8-samples
apt install tensorrt tensorrt-dev tensorrt-libs python3-libnvinfer python3-libnvinfer-dev uff-converter-tf onnx-graphsurgeon graphsurgeon-tf
apt install deepstream-6.2

2. å®‰è£…torchï¼Œä½¿ç”¨pip3å·¥å…·ä¸‹è½½è½¯ä»¶åŒ…
#åŠ -iå‚æ•°å¯ä»¥æŒ‡å®šå›½å†…ä¸‹è½½æº
apt install python3-pip libopenblas-dev
python3 -m pip install aiohttp opencv-python scipy=='1.5.3' -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install ./torch-2.1.0a0+41361538.nv23.06-cp38-cp38-linux_aarch64.whl -i https://pypi.tuna.tsinghua.edu.cn/simple
ã€é€šå¸¸ä½¿ç”¨pip3 freeze æˆ– pip3 listæŸ¥çœ‹ç³»ç»Ÿå®‰è£…çš„pythonåŒ…ã€‘

3. å®‰è£…torchvisionã€torchvisionæ˜¯ä¸€äº›å›¾åƒåº“ã€‘
apt install ffmpeg libavutil-dev libavcodec-dev libavformat-dev libavdevice-dev libavfilter-dev libswscale-dev libswresample-dev libswresample-dev libpostproc-dev libjpeg-dev libpng-dev
git clone https://github.com/pytorch/vision torchvision //ä¸‹è½½æºç 
tar -zpxvf vision-0.16.0.tar.gz
cd vision-0.16.0/ 
python3 setup.py install  	//ä»æºç ç¼–è¯‘torchvision
python3 setup.py bdist_wheel    //åˆ©ç”¨ç¼–è¯‘æˆåŠŸçš„æºç ç”Ÿæˆ*.whlæ–‡ä»¶,ç”Ÿæˆæ–‡ä»¶è·¯å¾„åœ¨/æºç æ ¹ç›®å½•/dist/
ã€æ³¨æ„ï¼šæºç ç¼–è¯‘å®‰è£…çš„torchvisionè·¯å¾„æ˜¯"/usr/lib/python3.8/site-packages/"ã€‘

ã€åˆ©ç”¨æºç ç¼–è¯‘ç”Ÿæˆ*.whlæ–‡ä»¶,å¯ç›´æ¥å®‰è£…torchvision-0.16.0-cp38-cp38-linux_aarch64.whlæ–‡ä»¶ã€‘

4. éªŒè¯torch torchvisionæ˜¯å¦å®‰è£…æˆåŠŸ
import torch
>>> print(torch.__version__)
>>> print('CUDA available: ' + str(torch.cuda.is_available()))
>>> print('cuDNN version: ' + str(torch.backends.cudnn.version()))
>>> a = torch.cuda.FloatTensor(2).zero_()
>>> print('Tensor a = ' + str(a))
>>> b = torch.randn(2).cuda()
>>> print('Tensor b = ' + str(b))
>>> c = a + b
>>> print('Tensor c = ' + str(c))

>>> import torchvision
>>> print(torchvision.__version__)

(å¯é€‰)5. å®‰è£…DeepStream SDKç¯å¢ƒ
å®‰è£…ä¾èµ–ï¼š
sudo apt install libssl1.1 libgstreamer1.0-0 gstreamer1.0-tools \
gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav \
libgstreamer-plugins-base1.0-dev libgstrtspserver-1.0-0 libjansson4 libyaml-cpp-dev

apt install -y ./deepstream-6.2_6.2.0-1_arm64.deb


ã€è·‘æ¨¡å‹è¿‡ç¨‹é€šè¿‡jtopæŸ¥çœ‹GPUæ€§èƒ½ã€‘
6. ä¸‹è½½yolov5ç½‘ç»œæ¨¡å‹:
git clone https://github.com/ultralytics/yolov5.git
å®‰è£…ç¯å¢ƒ:
pip3 install gitpython==3.1.30 numpy==1.22.2 setuptools==65.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install onnx onnxruntime opencv-python ultralytics -i https://pypi.tuna.tsinghua.edu.cn/simple
cd yolov5/
ä¸‹è½½æ¨¡å‹ï¼š
wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt
ã€å¤‡æ³¨ï¼šyolov5s.pt, yolov5m.pt, yolov5l.pt,yolov5x.pt, yolov5n.ptæ˜¯YOLOV5çš„ä¸åŒå˜ä½“,è¡¨ç¤ºä¸åŒå¤§å°å’Œå¤æ‚æ€§çš„æ¨¡å‹ã€‘
ã€ yolov5s-seg.pt, yolov5m-seg.ptè¡¨ç¤ºå®ä¾‹åˆ†å‰²æ˜¯æŒ‡å°†å›¾ç‰‡ä¸­å±äºç‰©ä½“ç±»åˆ«çš„åƒç´ è¯†åˆ«å‡ºæ¥å¹¶ä½œåˆ†ç±»ã€‘

python3 detect.py --weights yolov5s.pt   //åˆ©ç”¨yolov5s.ptæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œ
ã€è¿è¡Œç»“æœå¦‚ä¸‹, ç”Ÿæˆæ–‡ä»¶åœ¨runs/detectã€‘
YOLOv5 ğŸš€ v7.0-231-gc2f131a Python-3.8.10 torch-2.1.0a0+41361538.nv23.06 CUDA:0 (Orin, 14533MiB)
Fusing layers...
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/2 /mnt/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 211.0ms
image 2/2 /mnt/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 218.8ms
Speed: 3.3ms pre-process, 168.0ms inference, 10.5ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/detect/exp

python3 segment/predict.py --weights yolov5s-seg.pt //ä½¿ç”¨yolov5s-seg.ptæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†å‰²
ã€ç”Ÿæˆçš„æ–‡ä»¶åœ¨runs/predict-seg/expã€‘

apt install imagemagick //linuxä¸‹å›¾ç‰‡æŸ¥çœ‹å‘½ä»¤

7.è‡ªå®šä¹‰è®­ç»ƒæ•°æ®é›†
a. ä¸‹è½½æ•°æ®é›†å›¾ç‰‡ç´ æï¼Œç„¶åé€šè¿‡labelImgæˆ–labelmeå·¥å…·è¿›è¡Œä¸åˆ†ç±»æ ‡æ³¨, ä½¿ç”¨æ ‡æ³¨å·¥å…·æ ‡è®°å›¾åƒåï¼Œå°†æ ‡ç­¾å¯¼å‡ºä¸ºYOLOæ ¼å¼ï¼Œ
æ¯å¼ *.txtå›¾åƒä¸€ä¸ªæ–‡ä»¶ï¼ˆå¦‚æœå›¾åƒä¸­æ²¡æœ‰å¯¹è±¡ï¼Œåˆ™ä¸éœ€è¦*.txtæ–‡ä»¶ï¼‰
ç”Ÿæˆimages/å’Œlabels/:
  --> imaegs/:é‡Œé¢å­˜æ”¾ç´ æå›¾ç‰‡
  --> labels/:é‡Œé¢å­˜æ”¾æ ‡æ³¨çš„*.txtæ–‡ä»¶ï¼Œ
  --> æ–‡ä»¶*.txtè§„æ ¼,åŒ…å«class x_center y_center width height(ç±» æ ‡æ³¨xåæ ‡ æ ‡æ³¨yåæ ‡ å®½åº¦ é«˜åº¦)
b. å‡†å¤‡custom.yaml,æ”¾ç½®yolov5/data/ç›®å½•ä¸‹: yamlé‡Œé¢æŒ‡å®šYOLOv5çš„images,labelsç›®å½•ä½ç½®ä»¥åŠæœ‰å…³æˆ‘ä»¬çš„è‡ªå®šä¹‰ç±»çš„ä¿¡æ¯
Example(data/custom.yaml):
	path: ../datasets/hard-hat
	train: train/images
	val: valid/images
	test: test/images

	nc: 3
	names: ['head', 'helmet', 'person']
ã€å¤‡æ³¨ï¼šå¦å¤–ä¸€ç§æ–¹æ³•ç›´æ¥åœ¨Roboflowç½‘ç«™ä¸Šä¸‹è½½æ ‡æ³¨å¥½çš„æ•°æ®é›†ï¼Œé‡Œé¢æœ‰å·²ç»ç”Ÿæˆå¥½çš„imageså’Œlabelsï¼Œdata.yaml(é‡å‘½åcustom.yaml)ã€‘

c. æ¥ä¸‹æ¥ä¸ºè‡ªå®šä¹‰å¯¹è±¡æ£€æµ‹å™¨ç¼–å†™æ¨¡å‹é…ç½®æ–‡ä»¶,é€‰æ‹©äº†æœ€å°ã€æœ€å¿«çš„ YOLOv5 åŸºç¡€æ¨¡å‹-yolov5s.pt
cp yolov5/models/yolov5s.yaml  yolov5/models/custom.yaml  //æ‹·è´æ ‡å‡†ç½‘ç»œç»“æ„ï¼Œæ¥è®¾ç½®è‡ªå®šä¹‰çš„ç½‘ç»œç»“æ„
ç¼–è¾‘ç½‘ç»œçš„ç»“æ„, ä¿®æ”¹custom.yamlé‡Œé¢çš„ã€nc:ã€‘, å’Œdata/custom.yamlçš„ncä¸€è‡´, é€‚é…è‡ªå®šä¹‰æ•°æ®é›†

d. å‡†å¤‡å¥½ä»¥ä¸Šæ–‡ä»¶åå°±å¯ä»¥å¼€å§‹è®­ç»ƒ
python3 train.py --data=data/custom.yaml --img 640 --epochs 300 --cfg=models/custom-yolov5s.yaml --weights weights/yolov5s.pt

--data				è®¾ç½®æˆ‘ä»¬æ•°æ®é›†yamlæ–‡ä»¶çš„è·¯å¾„
--img				å®šä¹‰è¾“å…¥å›¾åƒå¤§å°
--epochs			å®šä¹‰è®­ç»ƒæ—¶æœŸçš„æ•°é‡
--cfg				æŒ‡å®šæˆ‘ä»¬çš„æ¨¡å‹yamlé…ç½®è·¯å¾„
--weights			æŒ‡å®šæƒé‡çš„è‡ªå®šä¹‰è·¯å¾„
--name				ç»“æœåç§°
--nosave			åªä¿å­˜æœ€åçš„æ£€æŸ¥ç‚¹
--cache ram or disk		ç¼“å­˜å›¾åƒä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦,éœ€è¦å¤§é‡ RAM/ç£ç›˜èµ„æº




å¤‡æ³¨ï¼š
ã€ ç”±äºå®˜æ–¹ç½‘ç«™åªæä¾› SBSA ARM CPUçš„TensorRTçš„DEBåŒ…ï¼Œæ²¡æœ‰æä¾›jetsonå¹³å°ï¼Œå› æ­¤é€šè¿‡TensorRTå®˜ç½‘ä¸‹è½½çš„DEBåŒ…ä¸é€‚ç”¨Jetsonå¹³å°ã€‘
ã€ç¦»çº¿å®‰è£…CUDAï¼ŒåŸºäºæ­¤CUDA-11.8ç‰ˆæœ¬æˆ–æ›´é«˜ä¸èƒ½ä½¿ç”¨TensorRTåŠŸèƒ½ä¼šæœ‰æŠ¥é”™é—®é¢˜ï¼ŒåŸå› æ˜¯NVå®˜æ–¹ä¸æä¾›JetPack5.1.1çš„CUDA11.8ä»¥ä¸Šç‰ˆæœ¬æ„å»ºTensorRTï¼Œå½“å‰JetPack5.1.1/JetPack5.1.2åªæ”¯æŒcuda11.4ç‰ˆæœ¬ã€‘
ã€ç›¸å…³æŠ¥é”™Error output:
ã€&&&& RUNNING TensorRT.sample_onnx_mnist [TensorRT v8503] # ./sample_onnx_mnist
[11/02/2023-17:01:07] [I] Building and running a GPU inference engine for Onnx MNIST
[11/02/2023-17:01:08] [I] [TRT] [MemUsageChange] Init CUDA: CPU +9, GPU +0, now: CPU 20, GPU 4247 (MiB)	[11/02/2023-17:01:27] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +174, GPU +164, now: CPU 248, GPU 4463 (MiB)
[11/02/2023-17:01:27] [W] [TRT] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[11/02/2023-17:01:29] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +556, GPU +525, now: CPU 804, GPU 4989 (MiB)
[11/02/2023-17:01:29] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +83, GPU +80, now: CPU 887, GPU 5069 (MiB)
[11/02/2023-17:01:29] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[11/02/2023-17:01:29] [W] [TRT] Skipping tactic 0x00000000000003e8 due to exception no kernel image is available for execution on the device
[11/02/2023-17:01:29] [W] [TRT] Skipping tactic 0x00000000000003ea due to exception Internal cuTensor permutate execute failed
[11/02/2023-17:01:29] [W] [TRT] Skipping tactic 0x0000000000000000 due to exception no kernel image is available for execution on the device
ã€‘

ã€ä»¥ä¸‹æ–¹æ³•å¯ä»¥è·‘Yolov5æ¨¡å‹ï¼Œä½†æ˜¯åœ¨åŸºäºonnxæ¨¡å‹è½¬æ¢tensorRTæ¨¡å‹ä¼šå¤±è´¥ï¼ŒåŸå› å¦‚ä¸Šã€‘
 # å®‰è£…ç¯å¢ƒ CUAD-11.8, cuDNN-8.6, torch-2.1.0, torchvision-0.16.0 #
1.ç¦»çº¿å®‰è£…ï¼š
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/arm64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-tegra-repo-ubuntu2004-11-8-local_11.8.0-1_arm64.deb
sudo dpkg -i cuda-tegra-repo-ubuntu2004-11-8-local_11.8.0-1_arm64.deb
sudo cp /var/cuda-tegra-repo-ubuntu2004-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda

# é…ç½®ç¯å¢ƒå˜é‡
export PATH=/usr/local/cuda-11.8/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda/compat${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}


# ä½¿ç”¨cuda-samples-12.3.tar.gzå¯ä»¥æµ‹è¯•cudaæ˜¯å¦å®‰è£…æˆåŠŸ
git clone https://github.com/nvidia/cuda-samples
cd cuda-samples-12.3/Samples/1_Utilities/deviceQuery
make clean && make

2. å®‰è£…cuDNN-8.6
dpkg -i cudnn-local-repo-ubuntu2004-8.6.0.163_1.0-1_arm64.de
cp /var/cudnn-local-repo-ubuntu2004-8.6.0.163/cudnn-local-04A93B30-keyring.gpg /usr/share/keyrings/
apt update && apt install libcudnn8 libcudnn8-dev libcudnn8-samples
è¿›å…¥/usr/src/cudnn_samples_v8/mnistCUDNN/éªŒè¯cudNNæ˜¯å¦å®‰è£…æˆåŠŸ

3. å®‰è£…torchï¼Œä½¿ç”¨pip3å·¥å…·ä¸‹è½½è½¯ä»¶åŒ…
#åŠ -iå‚æ•°å¯ä»¥æŒ‡å®šå›½å†…ä¸‹è½½æº
apt install python3-pip libopenblas-dev
pip3 install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple
python3 -m pip install aiohttp numpy=='1.19.4' scipy=='1.5.3' -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install ./torch-2.1.0a0+41361538.nv23.06-cp38-cp38-linux_aarch64.whl -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install setuptools==49.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
ã€é€šå¸¸ä½¿ç”¨pip3 freeze æˆ– pip3 listæŸ¥çœ‹ç³»ç»Ÿå®‰è£…çš„pythonåŒ…ã€‘

4. å®‰è£…torchvisionã€torchvisionæ˜¯ä¸€äº›å›¾åƒåº“ã€‘
apt install ffmpeg libavutil-dev libavcodec-dev libavformat-dev libavdevice-dev libavfilter-dev libswscale-dev libswresample-dev libswresample-dev libpostproc-dev libjpeg-dev libpng-dev
git clone https://github.com/pytorch/vision torchvision //ä¸‹è½½æºç 
tar -zpxvf vision-0.16.0.tar.gz
cd vision-0.16.0/ 
python3 setup.py install  	//ä»æºç ç¼–è¯‘torchvision
python3 setup.py bdist_wheel    //åˆ©ç”¨ç¼–è¯‘æˆåŠŸçš„æºç ç”Ÿæˆ*.whlæ–‡ä»¶,ç”Ÿæˆæ–‡ä»¶è·¯å¾„åœ¨/æºç æ ¹ç›®å½•/dist/
ã€æ³¨æ„ï¼šæºç ç¼–è¯‘å®‰è£…çš„torchvisionè·¯å¾„æ˜¯"/usr/lib/python3.8/site-packages/"ã€‘

ã€åˆ©ç”¨æºç ç¼–è¯‘ç”Ÿæˆ*.whlæ–‡ä»¶,å¯ç›´æ¥å®‰è£…torchvision-0.16.0-cp38-cp38-linux_aarch64.whlæ–‡ä»¶ã€‘

5. éªŒè¯torch torchvisionæ˜¯å¦å®‰è£…æˆåŠŸ
import torch
>>> print(torch.__version__)
>>> print('CUDA available: ' + str(torch.cuda.is_available()))
>>> print('cuDNN version: ' + str(torch.backends.cudnn.version()))
>>> a = torch.cuda.FloatTensor(2).zero_()
>>> print('Tensor a = ' + str(a))
>>> b = torch.randn(2).cuda()
>>> print('Tensor b = ' + str(b))
>>> c = a + b
>>> print('Tensor c = ' + str(c))

>>> import torchvision
>>> print(torchvision.__version__)


6. å®‰è£…DeepStream SDKç¯å¢ƒ
å®‰è£…ä¾èµ–ï¼š
sudo apt install libssl1.1 libgstreamer1.0-0 gstreamer1.0-tools \
gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav \
libgstreamer-plugins-base1.0-dev libgstrtspserver-1.0-0 libjansson4 libyaml-cpp-dev

apt install -y ./deepstream-6.2_6.2.0-1_arm64.deb


7. ä¸‹è½½yolov5ç½‘ç»œæ¨¡å‹:
git clone https://github.com/ultralytics/yolov5.git
å®‰è£…ç¯å¢ƒ:
pip3 install onnx onnxruntime opencv-python ultralytics -i https://pypi.tuna.tsinghua.edu.cn/simple
cd yolov5/
ä¸‹è½½æ¨¡å‹ï¼š
wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt

è½¬æ¢æ¨¡å‹æ–‡ä»¶
python3 export_yoloV5.py -w yolov5s.pt --dynamic   //ç”Ÿæˆ ONNX æ¨¡å‹æ–‡ä»¶(YOLOv5sç¤ºä¾‹)
å°†ç”Ÿæˆçš„ONNXæ¨¡å‹æ–‡ä»¶å’Œlabels.txt æ–‡ä»¶(å¦‚æœå·²ç”Ÿæˆ)å¤åˆ¶åˆ°è¯¥DeepStream-Yolo/
ã€å¤‡æ³¨ï¼šyolov5s.pt, yolov5m.pt, yolov5l.pt,yolov5x.pt, yolov5n.ptæ˜¯YOLOV5çš„ä¸åŒå˜ä½“,è¡¨ç¤ºä¸åŒå¤§å°å’Œå¤æ‚æ€§çš„æ¨¡å‹ã€‘
ã€ yolov5s-seg.pt, yolov5m-seg.ptè¡¨ç¤ºå®ä¾‹åˆ†å‰²æ˜¯æŒ‡å°†å›¾ç‰‡ä¸­å±äºç‰©ä½“ç±»åˆ«çš„åƒç´ è¯†åˆ«å‡ºæ¥å¹¶ä½œåˆ†ç±»ã€‘

python3 detect.py --weights yolov5s.pt   //åˆ©ç”¨yolov5s.ptæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œ
ã€è¿è¡Œç»“æœå¦‚ä¸‹, ç”Ÿæˆæ–‡ä»¶åœ¨runs/detectã€‘
YOLOv5 ğŸš€ v7.0-231-gc2f131a Python-3.8.10 torch-2.1.0a0+41361538.nv23.06 CUDA:0 (Orin, 14533MiB)
Fusing layers...
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/2 /mnt/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 211.0ms
image 2/2 /mnt/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 218.8ms
Speed: 3.3ms pre-process, 168.0ms inference, 10.5ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/detect/exp

python3 segment/predict.py --weights yolov5s-seg.pt //ä½¿ç”¨yolov5s-seg.ptæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†å‰²
ã€ç”Ÿæˆçš„æ–‡ä»¶åœ¨runs/predict-seg/expã€‘


å‚è€ƒé“¾æ¥ï¼š
https://github.com/marcoslucianops/DeepStream-Yolo/blob/master/docs/YOLOv5.md#3-download-the-model
https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048
https://github.com/pypa/setuptools/issues/3240
https://blog.51cto.com/u_15953612/6894961
